{"sections":[],"metadata":{"title":"temperature","roleHeading":"Instance Property","role":"symbol","modules":[{"name":"OpenAI"}],"symbolKind":"property","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Sd","text":"Double","kind":"typeIdentifier"},{"kind":"text","text":"?"}],"externalID":"s:6OpenAI9ChatQueryV11temperatureSdSgvp"},"schemaVersion":{"major":0,"minor":3,"patch":0},"variants":[{"paths":["\/documentation\/openai\/chatquery\/temperature"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature"},"kind":"symbol","primaryContentSections":[{"kind":"declarations","declarations":[{"languages":["swift"],"platforms":["macOS"],"tokens":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Sd","text":"Double","kind":"typeIdentifier"},{"text":"?","kind":"text"}]}]}],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"abstract":[{"type":"text","text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},{"type":"text","text":" "},{"text":"We generally recommend altering this or top_p but not both.","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"Defaults to 1"}],"references":{"doc://OpenAI/documentation/OpenAI/ChatQuery/temperature":{"title":"temperature","kind":"symbol","role":"symbol","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:Sd","text":"Double"},{"kind":"text","text":"?"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature","abstract":[{"type":"text","text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},{"text":" ","type":"text"},{"text":"We generally recommend altering this or top_p but not both.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"Defaults to 1"}],"type":"topic","url":"\/documentation\/openai\/chatquery\/temperature"},"doc://OpenAI/documentation/OpenAI":{"type":"topic","kind":"symbol","abstract":[],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","role":"collection","url":"\/documentation\/openai","title":"OpenAI"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"type":"topic","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ChatQuery","kind":"identifier"}],"navigatorTitle":[{"text":"ChatQuery","kind":"identifier"}],"url":"\/documentation\/openai\/chatquery","role":"symbol","abstract":[{"type":"text","text":"Creates a model response for the given chat conversation"},{"type":"text","text":" "},{"text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation","type":"text"}],"kind":"symbol","title":"ChatQuery"}}}