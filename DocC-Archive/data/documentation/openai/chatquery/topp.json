{"metadata":{"symbolKind":"property","title":"topP","externalID":"s:6OpenAI9ChatQueryV4topPSdSgvp","modules":[{"name":"OpenAI"}],"role":"symbol","roleHeading":"Instance Property","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"topP","kind":"identifier"},{"kind":"text","text":": "},{"text":"Double","preciseIdentifier":"s:Sd","kind":"typeIdentifier"},{"kind":"text","text":"?"}]},"sections":[],"kind":"symbol","schemaVersion":{"patch":0,"major":0,"minor":3},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/chatquery\/topp"]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/topP"},"abstract":[{"type":"text","text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."},{"text":" ","type":"text"},{"type":"text","text":"We generally recommend altering this or temperature but not both."},{"type":"text","text":" "},{"type":"text","text":"Defaults to 1"}],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"topP","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"platforms":["macOS"],"languages":["swift"]}]}],"references":{"doc://OpenAI/documentation/OpenAI/ChatQuery/topP":{"url":"\/documentation\/openai\/chatquery\/topp","type":"topic","abstract":[{"text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"We generally recommend altering this or temperature but not both."},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}],"kind":"symbol","title":"topP","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"topP","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"role":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/topP"},"doc://OpenAI/documentation/OpenAI":{"url":"\/documentation\/openai","title":"OpenAI","role":"collection","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","kind":"symbol","abstract":[],"type":"topic"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"kind":"symbol","navigatorTitle":[{"text":"ChatQuery","kind":"identifier"}],"role":"symbol","type":"topic","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","abstract":[{"type":"text","text":"Creates a model response for the given chat conversation"},{"type":"text","text":" "},{"text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation","type":"text"}],"url":"\/documentation\/openai\/chatquery","title":"ChatQuery","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ChatQuery","kind":"identifier"}]}}}