{"identifier":{"url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/maxTokens","interfaceLanguage":"swift"},"sections":[],"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"tokens":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"maxTokens","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"text":"?","kind":"text"}],"languages":["swift"]}]}],"abstract":[{"text":"The maximum number of tokens to generate in the completion.","type":"text"},{"text":" ","type":"text"},{"text":"The total length of input tokens and generated tokens is limited by the model’s context length.","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"https:\/\/platform.openai.com\/tokenizer"}],"metadata":{"externalID":"s:6OpenAI9ChatQueryV9maxTokensSiSgvp","roleHeading":"Instance Property","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"maxTokens"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:Si","text":"Int"},{"text":"?","kind":"text"}],"symbolKind":"property","modules":[{"name":"OpenAI"}],"role":"symbol","title":"maxTokens"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/chatquery\/maxtokens"]}],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"schemaVersion":{"minor":3,"patch":0,"major":0},"kind":"symbol","references":{"doc://OpenAI/documentation/OpenAI/ChatQuery/maxTokens":{"role":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/maxTokens","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"kind":"identifier","text":"maxTokens"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"text":"?","kind":"text"}],"abstract":[{"type":"text","text":"The maximum number of tokens to generate in the completion."},{"text":" ","type":"text"},{"text":"The total length of input tokens and generated tokens is limited by the model’s context length.","type":"text"},{"text":" ","type":"text"},{"text":"https:\/\/platform.openai.com\/tokenizer","type":"text"}],"url":"\/documentation\/openai\/chatquery\/maxtokens","type":"topic","kind":"symbol","title":"maxTokens"},"doc://OpenAI/documentation/OpenAI":{"type":"topic","abstract":[],"role":"collection","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","title":"OpenAI","url":"\/documentation\/openai","kind":"symbol"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"title":"ChatQuery","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"ChatQuery","kind":"identifier"}],"navigatorTitle":[{"text":"ChatQuery","kind":"identifier"}],"url":"\/documentation\/openai\/chatquery","abstract":[{"text":"Creates a model response for the given chat conversation","type":"text"},{"type":"text","text":" "},{"type":"text","text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation"}],"kind":"symbol","type":"topic","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","role":"symbol"}}}