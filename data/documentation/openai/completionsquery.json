{"kind":"symbol","sections":[],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI"]]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery"},"metadata":{"externalID":"s:6OpenAI16CompletionsQueryV","symbolKind":"struct","modules":[{"name":"OpenAI"}],"navigatorTitle":[{"text":"CompletionsQuery","kind":"identifier"}],"role":"symbol","title":"CompletionsQuery","roleHeading":"Structure","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"CompletionsQuery","kind":"identifier"}]},"relationshipsSections":[{"identifiers":["doc:\/\/OpenAI\/Se","doc:\/\/OpenAI\/SE"],"title":"Conforms To","kind":"relationships","type":"conformsTo"}],"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/init(from:)","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/init(model:prompt:temperature:maxTokens:topP:frequencyPenalty:presencePenalty:stop:user:)"]},{"identifiers":["doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/frequencyPenalty","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/maxTokens","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/model","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/presencePenalty","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/prompt","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/stop","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/temperature","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/topP","doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/user"],"title":"Instance Properties"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/completionsquery"]}],"primaryContentSections":[{"declarations":[{"languages":["swift"],"platforms":["macOS"],"tokens":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"CompletionsQuery","kind":"identifier"}]}],"kind":"declarations"}],"schemaVersion":{"minor":3,"patch":0,"major":0},"references":{"doc://OpenAI/SE":{"type":"unresolvable","title":"Swift.Encodable","identifier":"doc:\/\/OpenAI\/SE"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/stop":{"abstract":[{"type":"text","text":"Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence."}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/stop","role":"symbol","type":"topic","title":"stop","url":"\/documentation\/openai\/completionsquery\/stop","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"stop","kind":"identifier"},{"text":": [","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"text":"]?","kind":"text"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/prompt":{"abstract":[{"text":"The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/prompt","role":"symbol","title":"prompt","type":"topic","url":"\/documentation\/openai\/completionsquery\/prompt","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"prompt","kind":"identifier"},{"kind":"text","text":": "},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery":{"url":"\/documentation\/openai\/completionsquery","abstract":[],"kind":"symbol","role":"symbol","navigatorTitle":[{"kind":"identifier","text":"CompletionsQuery"}],"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"CompletionsQuery","kind":"identifier"}],"title":"CompletionsQuery","type":"topic","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/frequencyPenalty":{"abstract":[{"text":"Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/frequencyPenalty","role":"symbol","title":"frequencyPenalty","type":"topic","url":"\/documentation\/openai\/completionsquery\/frequencypenalty","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"frequencyPenalty","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"kind":"symbol"},"doc://OpenAI/Se":{"type":"unresolvable","title":"Swift.Decodable","identifier":"doc:\/\/OpenAI\/Se"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/presencePenalty":{"abstract":[{"type":"text","text":"Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics."}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/presencePenalty","role":"symbol","type":"topic","title":"presencePenalty","url":"\/documentation\/openai\/completionsquery\/presencepenalty","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"presencePenalty","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Sd","kind":"typeIdentifier","text":"Double"},{"text":"?","kind":"text"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI":{"url":"\/documentation\/openai","type":"topic","abstract":[],"kind":"symbol","title":"OpenAI","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","role":"collection"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/model":{"title":"model","kind":"symbol","type":"topic","url":"\/documentation\/openai\/completionsquery\/model","role":"symbol","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"model"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:6OpenAI5Modela","text":"Model","kind":"typeIdentifier"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/model","abstract":[{"type":"text","text":"ID of the model to use."}]},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/temperature":{"abstract":[{"text":"What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/temperature","role":"symbol","title":"temperature","type":"topic","url":"\/documentation\/openai\/completionsquery\/temperature","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/init(from:)":{"abstract":[],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/init(from:)","role":"symbol","type":"topic","title":"init(from:)","url":"\/documentation\/openai\/completionsquery\/init(from:)","fragments":[{"kind":"identifier","text":"init"},{"text":"(","kind":"text"},{"text":"from","kind":"externalParam"},{"text":": any ","kind":"text"},{"text":"Decoder","kind":"typeIdentifier","preciseIdentifier":"s:s7DecoderP"},{"kind":"text","text":") "},{"text":"throws","kind":"keyword"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/maxTokens":{"abstract":[{"text":"The maximum number of tokens to generate in the completion.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/maxTokens","role":"symbol","title":"maxTokens","type":"topic","url":"\/documentation\/openai\/completionsquery\/maxtokens","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"maxTokens","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/init(model:prompt:temperature:maxTokens:topP:frequencyPenalty:presencePenalty:stop:user:)":{"abstract":[],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/init(model:prompt:temperature:maxTokens:topP:frequencyPenalty:presencePenalty:stop:user:)","role":"symbol","type":"topic","title":"init(model:prompt:temperature:maxTokens:topP:frequencyPenalty:presencePenalty:stop:user:)","url":"\/documentation\/openai\/completionsquery\/init(model:prompt:temperature:maxtokens:topp:frequencypenalty:presencepenalty:stop:user:)","fragments":[{"kind":"identifier","text":"init"},{"text":"(","kind":"text"},{"text":"model","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Model","kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI5Modela"},{"kind":"text","text":", "},{"text":"prompt","kind":"externalParam"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"text":", ","kind":"text"},{"text":"temperature","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?, ","kind":"text"},{"text":"maxTokens","kind":"externalParam"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:Si","text":"Int"},{"text":"?, ","kind":"text"},{"kind":"externalParam","text":"topP"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"frequencyPenalty"},{"kind":"text","text":": "},{"text":"Double","preciseIdentifier":"s:Sd","kind":"typeIdentifier"},{"text":"?, ","kind":"text"},{"text":"presencePenalty","kind":"externalParam"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Sd","text":"Double","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"text":"stop","kind":"externalParam"},{"kind":"text","text":": ["},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"text":"]?, ","kind":"text"},{"kind":"externalParam","text":"user"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"kind":"text","text":"?)"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/user":{"abstract":[{"text":"A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/user","role":"symbol","title":"user","type":"topic","url":"\/documentation\/openai\/completionsquery\/user","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"user"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"kind":"text","text":"?"}],"kind":"symbol"},"doc://OpenAI/documentation/OpenAI/CompletionsQuery/topP":{"abstract":[{"text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.","type":"text"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/CompletionsQuery\/topP","role":"symbol","title":"topP","type":"topic","url":"\/documentation\/openai\/completionsquery\/topp","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"topP"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:Sd","text":"Double"},{"kind":"text","text":"?"}],"kind":"symbol"}}}