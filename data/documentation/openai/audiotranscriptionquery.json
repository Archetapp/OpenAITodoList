{"kind":"symbol","primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"tokens":[{"text":"struct","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioTranscriptionQuery"}],"languages":["swift"]}]}],"topicSections":[{"identifiers":["doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/init(file:fileType:model:prompt:temperature:language:responseFormat:)","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/init(from:)"],"title":"Initializers"},{"title":"Instance Properties","identifiers":["doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/file","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/fileType-swift.property","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/language","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/model","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/prompt","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/responseFormat-swift.property","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/temperature"]},{"title":"Enumerations","identifiers":["doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/FileType-swift.enum","doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/ResponseFormat-swift.enum"]}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/audiotranscriptionquery"]}],"identifier":{"url":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery","interfaceLanguage":"swift"},"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI"]]},"relationshipsSections":[{"title":"Conforms To","identifiers":["doc:\/\/OpenAI\/Se","doc:\/\/OpenAI\/SE"],"kind":"relationships","type":"conformsTo"}],"metadata":{"roleHeading":"Structure","modules":[{"name":"OpenAI"}],"navigatorTitle":[{"kind":"identifier","text":"AudioTranscriptionQuery"}],"externalID":"s:6OpenAI23AudioTranscriptionQueryV","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"AudioTranscriptionQuery"}],"symbolKind":"struct","role":"symbol","title":"AudioTranscriptionQuery"},"references":{"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/prompt":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/prompt","url":"\/documentation\/openai\/audiotranscriptionquery\/prompt","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"prompt"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"text":"?","kind":"text"}],"role":"symbol","abstract":[{"type":"text","text":"An optional text to guide the modelâ€™s style or continue a previous audio segment. The prompt should match the audio language."}],"title":"prompt"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/temperature":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/temperature","url":"\/documentation\/openai\/audiotranscriptionquery\/temperature","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"role":"symbol","abstract":[{"type":"text","text":"The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit."},{"type":"text","text":" "},{"text":"Defaults to 0","type":"text"}],"title":"temperature"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/FileType-swift.enum":{"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/FileType-swift.enum","title":"AudioTranscriptionQuery.FileType","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"FileType","kind":"identifier"}],"kind":"symbol","navigatorTitle":[{"text":"FileType","kind":"identifier"}],"abstract":[],"url":"\/documentation\/openai\/audiotranscriptionquery\/filetype-swift.enum","role":"symbol","type":"topic"},"doc://OpenAI/SE":{"identifier":"doc:\/\/OpenAI\/SE","title":"Swift.Encodable","type":"unresolvable"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/fileType-swift.property":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/fileType-swift.property","url":"\/documentation\/openai\/audiotranscriptionquery\/filetype-swift.property","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"fileType"},{"kind":"text","text":": `Self`"},{"kind":"text","text":"."},{"text":"FileType","kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI23AudioTranscriptionQueryV8FileTypeO"}],"role":"symbol","abstract":[],"title":"fileType"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/file":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/file","url":"\/documentation\/openai\/audiotranscriptionquery\/file","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"file"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:10Foundation4DataV","text":"Data","kind":"typeIdentifier"}],"role":"symbol","abstract":[{"text":"The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.","type":"text"}],"title":"file"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/responseFormat-swift.property":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/responseFormat-swift.property","url":"\/documentation\/openai\/audiotranscriptionquery\/responseformat-swift.property","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"responseFormat"},{"text":": `Self`","kind":"text"},{"kind":"text","text":"."},{"text":"ResponseFormat","kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI23AudioTranscriptionQueryV14ResponseFormatO"},{"kind":"text","text":"?"}],"role":"symbol","abstract":[{"text":"The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"Defaults to json"}],"title":"responseFormat"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/model":{"title":"model","role":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/model","url":"\/documentation\/openai\/audiotranscriptionquery\/model","abstract":[{"type":"text","text":"ID of the model to use. Only whisper-1 is currently available."}],"kind":"symbol","type":"topic","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"text":"model","kind":"identifier"},{"kind":"text","text":": "},{"text":"Model","kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI5Modela"}]},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/init(file:fileType:model:prompt:temperature:language:responseFormat:)":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/init(file:fileType:model:prompt:temperature:language:responseFormat:)","url":"\/documentation\/openai\/audiotranscriptionquery\/init(file:filetype:model:prompt:temperature:language:responseformat:)","fragments":[{"text":"init","kind":"identifier"},{"text":"(","kind":"text"},{"text":"file","kind":"externalParam"},{"kind":"text","text":": "},{"text":"Data","kind":"typeIdentifier","preciseIdentifier":"s:10Foundation4DataV"},{"kind":"text","text":", "},{"text":"fileType","kind":"externalParam"},{"kind":"text","text":": `Self`"},{"kind":"text","text":"."},{"kind":"typeIdentifier","text":"FileType","preciseIdentifier":"s:6OpenAI23AudioTranscriptionQueryV8FileTypeO"},{"text":", ","kind":"text"},{"kind":"externalParam","text":"model"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI5Modela","text":"Model"},{"text":", ","kind":"text"},{"text":"prompt","kind":"externalParam"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"text":"?, ","kind":"text"},{"text":"temperature","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"language"},{"kind":"text","text":": "},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"responseFormat"},{"kind":"text","text":": `Self`"},{"kind":"text","text":"."},{"text":"ResponseFormat","kind":"typeIdentifier","preciseIdentifier":"s:6OpenAI23AudioTranscriptionQueryV14ResponseFormatO"},{"text":"?)","kind":"text"}],"role":"symbol","abstract":[],"title":"init(file:fileType:model:prompt:temperature:language:responseFormat:)"},"doc://OpenAI/documentation/OpenAI":{"abstract":[],"type":"topic","title":"OpenAI","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","kind":"symbol","role":"collection","url":"\/documentation\/openai"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery":{"title":"AudioTranscriptionQuery","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioTranscriptionQuery","kind":"identifier"}],"kind":"symbol","navigatorTitle":[{"text":"AudioTranscriptionQuery","kind":"identifier"}],"abstract":[],"url":"\/documentation\/openai\/audiotranscriptionquery","role":"symbol","type":"topic"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/ResponseFormat-swift.enum":{"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/ResponseFormat-swift.enum","role":"symbol","navigatorTitle":[{"text":"ResponseFormat","kind":"identifier"}],"title":"AudioTranscriptionQuery.ResponseFormat","abstract":[],"type":"topic","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"text":"ResponseFormat","kind":"identifier"}],"url":"\/documentation\/openai\/audiotranscriptionquery\/responseformat-swift.enum","kind":"symbol"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/init(from:)":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/init(from:)","url":"\/documentation\/openai\/audiotranscriptionquery\/init(from:)","fragments":[{"text":"init","kind":"identifier"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"from"},{"kind":"text","text":": any "},{"kind":"typeIdentifier","preciseIdentifier":"s:s7DecoderP","text":"Decoder"},{"text":") ","kind":"text"},{"kind":"keyword","text":"throws"}],"role":"symbol","abstract":[],"title":"init(from:)"},"doc://OpenAI/documentation/OpenAI/AudioTranscriptionQuery/language":{"type":"topic","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/AudioTranscriptionQuery\/language","url":"\/documentation\/openai\/audiotranscriptionquery\/language","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"language","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"kind":"text","text":"?"}],"role":"symbol","abstract":[{"type":"text","text":"The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency."},{"type":"text","text":" "},{"type":"text","text":"https:\/\/platform.openai.com\/docs\/guides\/speech-to-text\/prompting"}],"title":"language"},"doc://OpenAI/Se":{"type":"unresolvable","identifier":"doc:\/\/OpenAI\/Se","title":"Swift.Decodable"}}}