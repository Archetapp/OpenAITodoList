{"kind":"symbol","metadata":{"fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"role":"symbol","externalID":"s:6OpenAI9ChatQueryV11temperatureSdSgvp","roleHeading":"Instance Property","modules":[{"name":"OpenAI"}],"title":"temperature","symbolKind":"property"},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/chatquery\/temperature"]}],"sections":[],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"schemaVersion":{"minor":3,"major":0,"patch":0},"abstract":[{"type":"text","text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},{"text":" ","type":"text"},{"text":"We generally recommend altering this or top_p but not both.","type":"text"},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}],"primaryContentSections":[{"declarations":[{"languages":["swift"],"tokens":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Sd","text":"Double","kind":"typeIdentifier"},{"text":"?","kind":"text"}],"platforms":["macOS"]}],"kind":"declarations"}],"references":{"doc://OpenAI/documentation/OpenAI/ChatQuery/temperature":{"kind":"symbol","title":"temperature","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature","type":"topic","url":"\/documentation\/openai\/chatquery\/temperature","abstract":[{"type":"text","text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},{"text":" ","type":"text"},{"type":"text","text":"We generally recommend altering this or top_p but not both."},{"type":"text","text":" "},{"type":"text","text":"Defaults to 1"}],"fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"temperature","kind":"identifier"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:Sd","text":"Double"},{"text":"?","kind":"text"}],"role":"symbol"},"doc://OpenAI/documentation/OpenAI":{"url":"\/documentation\/openai","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","abstract":[],"type":"topic","role":"collection","kind":"symbol","title":"OpenAI"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"role":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"text":"ChatQuery","kind":"identifier"}],"kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","navigatorTitle":[{"text":"ChatQuery","kind":"identifier"}],"abstract":[{"text":"Creates a model response for the given chat conversation","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation"}],"url":"\/documentation\/openai\/chatquery","title":"ChatQuery","type":"topic"}}}