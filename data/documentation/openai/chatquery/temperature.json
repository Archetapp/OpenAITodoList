{"schemaVersion":{"major":0,"minor":3,"patch":0},"kind":"symbol","variants":[{"paths":["\/documentation\/openai\/chatquery\/temperature"],"traits":[{"interfaceLanguage":"swift"}]}],"abstract":[{"text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.","type":"text"},{"type":"text","text":" "},{"text":"We generally recommend altering this or top_p but not both.","type":"text"},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}],"metadata":{"fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:Sd","kind":"typeIdentifier","text":"Double"},{"text":"?","kind":"text"}],"symbolKind":"property","role":"symbol","title":"temperature","externalID":"s:6OpenAI9ChatQueryV11temperatureSdSgvp","modules":[{"name":"OpenAI"}],"roleHeading":"Instance Property"},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature"},"sections":[],"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["macOS"],"languages":["swift"],"tokens":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"temperature"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?","kind":"text"}]}]}],"references":{"doc://OpenAI/documentation/OpenAI/ChatQuery":{"abstract":[{"text":"Creates a model response for the given chat conversation","type":"text"},{"type":"text","text":" "},{"text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"ChatQuery"}],"type":"topic","title":"ChatQuery","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","kind":"symbol","role":"symbol","url":"\/documentation\/openai\/chatquery","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"ChatQuery"}]},"doc://OpenAI/documentation/OpenAI":{"abstract":[],"type":"topic","title":"OpenAI","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","kind":"symbol","role":"collection","url":"\/documentation\/openai"},"doc://OpenAI/documentation/OpenAI/ChatQuery/temperature":{"title":"temperature","role":"symbol","url":"\/documentation\/openai\/chatquery\/temperature","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/temperature","type":"topic","abstract":[{"text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.","type":"text"},{"type":"text","text":" "},{"type":"text","text":"We generally recommend altering this or top_p but not both."},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}],"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?","kind":"text"}],"kind":"symbol"}}}