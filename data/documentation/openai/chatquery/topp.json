{"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"metadata":{"title":"topP","role":"symbol","fragments":[{"kind":"keyword","text":"let"},{"text":" ","kind":"text"},{"kind":"identifier","text":"topP"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Sd","text":"Double","kind":"typeIdentifier"},{"text":"?","kind":"text"}],"externalID":"s:6OpenAI9ChatQueryV4topPSdSgvp","modules":[{"name":"OpenAI"}],"roleHeading":"Instance Property","symbolKind":"property"},"abstract":[{"type":"text","text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."},{"text":" ","type":"text"},{"text":"We generally recommend altering this or temperature but not both.","type":"text"},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}],"variants":[{"paths":["\/documentation\/openai\/chatquery\/topp"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/topP"},"primaryContentSections":[{"declarations":[{"languages":["swift"],"tokens":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"topP","kind":"identifier"},{"kind":"text","text":": "},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?","kind":"text"}],"platforms":["macOS"]}],"kind":"declarations"}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"kind":"symbol","references":{"doc://OpenAI/documentation/OpenAI":{"kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI","title":"OpenAI","type":"topic","abstract":[],"url":"\/documentation\/openai","role":"collection"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"type":"topic","kind":"symbol","abstract":[{"type":"text","text":"Creates a model response for the given chat conversation"},{"text":" ","type":"text"},{"type":"text","text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation"}],"role":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"kind":"identifier","text":"ChatQuery"}],"navigatorTitle":[{"kind":"identifier","text":"ChatQuery"}],"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","url":"\/documentation\/openai\/chatquery","title":"ChatQuery"},"doc://OpenAI/documentation/OpenAI/ChatQuery/topP":{"title":"topP","kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/topP","url":"\/documentation\/openai\/chatquery\/topp","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"topP"},{"kind":"text","text":": "},{"text":"Double","preciseIdentifier":"s:Sd","kind":"typeIdentifier"},{"text":"?","kind":"text"}],"role":"symbol","type":"topic","abstract":[{"type":"text","text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."},{"text":" ","type":"text"},{"type":"text","text":"We generally recommend altering this or temperature but not both."},{"type":"text","text":" "},{"text":"Defaults to 1","type":"text"}]}}}