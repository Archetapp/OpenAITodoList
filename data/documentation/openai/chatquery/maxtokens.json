{"hierarchy":{"paths":[["doc:\/\/OpenAI\/documentation\/OpenAI","doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery"]]},"abstract":[{"text":"The maximum number of tokens to generate in the completion.","type":"text"},{"text":" ","type":"text"},{"text":"The total length of input tokens and generated tokens is limited by the model’s context length.","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"https:\/\/platform.openai.com\/tokenizer"}],"schemaVersion":{"patch":0,"minor":3,"major":0},"metadata":{"symbolKind":"property","role":"symbol","title":"maxTokens","externalID":"s:6OpenAI9ChatQueryV9maxTokensSiSgvp","modules":[{"name":"OpenAI"}],"roleHeading":"Instance Property","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"maxTokens","kind":"identifier"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"text":"?","kind":"text"}]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/maxTokens"},"sections":[],"primaryContentSections":[{"declarations":[{"languages":["swift"],"platforms":["macOS"],"tokens":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"maxTokens","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Int","kind":"typeIdentifier","preciseIdentifier":"s:Si"},{"text":"?","kind":"text"}]}],"kind":"declarations"}],"kind":"symbol","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openai\/chatquery\/maxtokens"]}],"references":{"doc://OpenAI/documentation/OpenAI/ChatQuery/maxTokens":{"kind":"symbol","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery\/maxTokens","fragments":[{"text":"let","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:Si","text":"Int"},{"text":"?","kind":"text"}],"role":"symbol","abstract":[{"type":"text","text":"The maximum number of tokens to generate in the completion."},{"text":" ","type":"text"},{"type":"text","text":"The total length of input tokens and generated tokens is limited by the model’s context length."},{"text":" ","type":"text"},{"type":"text","text":"https:\/\/platform.openai.com\/tokenizer"}],"url":"\/documentation\/openai\/chatquery\/maxtokens","type":"topic","title":"maxTokens"},"doc://OpenAI/documentation/OpenAI/ChatQuery":{"identifier":"doc:\/\/OpenAI\/documentation\/OpenAI\/ChatQuery","type":"topic","url":"\/documentation\/openai\/chatquery","title":"ChatQuery","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ChatQuery","kind":"identifier"}],"navigatorTitle":[{"text":"ChatQuery","kind":"identifier"}],"kind":"symbol","role":"symbol","abstract":[{"text":"Creates a model response for the given chat conversation","type":"text"},{"text":" ","type":"text"},{"text":"https:\/\/platform.openai.com\/docs\/guides\/text-generation","type":"text"}]},"doc://OpenAI/documentation/OpenAI":{"abstract":[],"role":"collection","url":"\/documentation\/openai","title":"OpenAI","kind":"symbol","type":"topic","identifier":"doc:\/\/OpenAI\/documentation\/OpenAI"}}}